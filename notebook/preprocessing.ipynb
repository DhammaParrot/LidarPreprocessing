{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit ('lidar3')",
   "metadata": {
    "interpreter": {
     "hash": "7ef75a84bf6fa82b62fc473c1722544d9914ff54c37670fd4887eee6a1b6a790"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import laspy\n",
    "import fiona\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas\n",
    "import laspy\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon\n",
    "import open3d as o3d\n",
    "import os\n",
    "from os import listdir,mkdir\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!find . -name \".DS_Store\" -delete\n",
    "shape = fiona.open(\"/Users/parrot/Envs/Lidar_Repo/resources/2019_angkormap/Master/AngkorMaster.shp/archaeology.shp\")\n",
    "#voxel size\n",
    "voxel_size=1\n",
    "#number of sectors/chunks in one direction \n",
    "cropnum=10\n",
    "directory=\"testdata\"\n",
    "child_directory=\"las\"\n",
    "parent_dir=\"/Users/parrot/Envs/Lidar_Repo/data/\"\n",
    "path = os.path.join(parent_dir, child_directory, directory) \n",
    "for files in listdir(path):\n",
    "    print(files)\n",
    "    fullpath=os.path.join(path,files)\n",
    "    print(fullpath)\n",
    "    inFile = laspy.file.File(fullpath, mode = \"r\")\n",
    "    splitat = 10\n",
    "    s =files[0:splitat]\n",
    "    suffix = '.xyz'\n",
    "    txtfullpath=os.path.join(parent_dir, \"txt/testdata\",s + suffix)\n",
    "    datasetfull = np.vstack([inFile.X/100, inFile.Y/100,inFile.Z/100]).transpose()\n",
    "    np.savetxt(txtfullpath, datasetfull)\n",
    "    pcd = o3d.io.read_point_cloud(txtfullpath)\n",
    "    #downsampling pc\n",
    "    downpcd = pcd.voxel_down_sample(voxel_size)\n",
    "    dataset = o3d.np.asarray(downpcd.points)[:,0:2]\n",
    "    zval=o3d.np.asarray(downpcd.points)[:,2]\n",
    "    splitat = 5\n",
    "    l, r =files[1:splitat], files[splitat:10]\n",
    "    xmin=100*int(l)\n",
    "    ymin=100*int(r)\n",
    "    xmax=100*(int(l)+5)\n",
    "    ymax=100*(int(r)+5)\n",
    "    #find which polygons are inside boundary box of the pc \n",
    "    hits=list(shape.items(bbox=(xmin, ymin, xmax, ymax)))\n",
    "    \n",
    "    zval=zval.tolist()\n",
    "    fullarray=[]\n",
    "    fullzeroarray=[]\n",
    "    #iterate over the polygons in the pointcloud\n",
    "    for m in range(len(hits)-1):\n",
    "        \n",
    "        polynum=m\n",
    "        \n",
    "        #iterate over the coordinates of the polygon\n",
    "        for j in range(len(hits[polynum][1]['geometry']['coordinates'])):\n",
    "        \n",
    "            print('polygon with this is id is th',j)\n",
    "            \n",
    "            unpacklist=hits[polynum][1]['geometry']['coordinates'][j]\n",
    "               \n",
    "            if len(unpacklist)==1:\n",
    "                \n",
    "                unpacklist=unpacklist[0]\n",
    "                \n",
    "            \n",
    "            polygon=Polygon(unpacklist)       \n",
    "            array = []\n",
    "            zeroarray=[]\n",
    "            #find which pc points lie inside these polygons\n",
    "            for i in range(np.shape(dataset)[0]):\n",
    "                point=Point(dataset[i,:])\n",
    "                if point.within(polygon)==True:\n",
    "                    array.append(i)\n",
    "               \n",
    "        fullarray.append(array)\n",
    "    ################    \n",
    "    ################\n",
    "    \n",
    "    dp=dataset.tolist()\n",
    "    getgen=[]\n",
    "    for ida in range(len(fullarray)):\n",
    "        \n",
    "        for idx,l in enumerate(fullarray[ida]):\n",
    "            \n",
    "    #append the feature type of the polygon to the 3d points \n",
    "            dp[l].extend((zval[l],hits[ida][1]['properties']['type']))\n",
    "\n",
    "    for i in range(len(dp)):\n",
    "        if len(dp[i])==2:\n",
    "            dp[i].extend((zval[i],0))\n",
    "\n",
    "\n",
    "    splitat = 5\n",
    "    l, r =files[1:splitat], files[splitat:10]\n",
    "\n",
    "    #define the extent of the sectors/chunks \n",
    "    xspace=(xmax-xmin)/cropnum\n",
    "    yspace=(ymax-ymin)/cropnum\n",
    "    ls=[]\n",
    "\n",
    "    #find which sectors actually contain points with labels\n",
    "    for k in range(len(dp)): \n",
    "        \n",
    "        for i, j in itertools.product(range(cropnum-1), range(cropnum-1)):\n",
    "            if (xmin+xspace*(i)<dp[k][0]<xmin+xspace*(i+1)) & (ymin+yspace*(j)<dp[k][1]<ymin+yspace*(j+1)) & (dp[k][3]!=0):\n",
    "                ls.append((i,j)) if (i,j) not in ls else ls\n",
    "    #print(ls)\n",
    "    getem=[]      \n",
    "#extract only the points that lie inside sectors with labels\n",
    "\n",
    "    xspace=(xmax-xmin)/cropnum\n",
    "    yspace=(ymax-ymin)/cropnum\n",
    "    for s, t in ls:\n",
    "        get=[]\n",
    "        for k in range(len(dp)):\n",
    "            \n",
    "            if (xmin+xspace*(s)<dp[k][0]<xmin+xspace*(s+1)) & (ymin+yspace*(t)<dp[k][1]<ymin+yspace*(t+1)):\n",
    "                get.append(dp[k])\n",
    "                \n",
    "        getem.append(get)\n",
    "    \n",
    "\n",
    "    getem_dpl = [[] for _ in range(lengetem)]\n",
    "\n",
    "    #this section deals with points that have more than one label. \n",
    "    for ia in range(len(getem)):\n",
    "        for ib in range(len(getem[ia])):\n",
    "            if len(getem[ia][ib])<5:\n",
    "            \n",
    "                getem_dpl[ia].insert(ib,getem[ia][ib][0:4])\n",
    "\n",
    "            else:\n",
    "                ls=list(range(2,len(getem[ia][ib]),2))\n",
    "             \n",
    "                for s,k in enumerate(ls):\n",
    "                    \n",
    "                    lr=[0,1,k,k+1]\n",
    "                    a=np.array(getem[ia][ib])[lr]\n",
    "                    getem_dpl[ia].append(list(a))\n",
    "\n",
    "    directory2=\"testdataout\"\n",
    "    child_directory2=\"txt\"\n",
    "    parent_dir2=\"/Users/parrot/Envs/Lidar_Repo/data/\"\n",
    "    path2 = os.path.join(parent_dir2, child_directory2, directory2) \n",
    "\n",
    "    for i in range(len(getem_dpl)):\n",
    "        \n",
    "        splitat = 10\n",
    "        s =files[0:splitat]\n",
    "        print(s)\n",
    "        suffix = '.xyz'\n",
    "        txtfullpath2=os.path.join(parent_dir2, \"txt/testdataout\",s +'_'+str(i) + suffix)\n",
    "        np.savetxt(txtfullpath2, getem_dpl[i])\n",
    "\n",
    " \n",
    "################\n",
    "################\n"
   ]
  }
 ]
}