{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit ('lidar3')",
   "metadata": {
    "interpreter": {
     "hash": "7ef75a84bf6fa82b62fc473c1722544d9914ff54c37670fd4887eee6a1b6a790"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "import laspy\n",
    "import fiona\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas\n",
    "import laspy\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon\n",
    "import open3d as o3d\n",
    "import os\n",
    "from os import listdir,mkdir\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Add Path to the Archeology Shape file Eg: ~/LidarPreProcessing/resources/archaeology.shp\n",
    "shape = fiona.open(\"Path/to/archeology.shp\")\n",
    "#Define voxel size\n",
    "voxel_size=1\n",
    "#Define number of sectors in one direction\n",
    "cropnum=10\n",
    "# Add Path to data directory Eg: ~/LidarPreProcessing/data/\n",
    "parent_dir=\"Path/to/data/directory\"\n",
    "#################################\n",
    "directory=\"testdata\"\n",
    "#sub directory where .las files go\n",
    "child_directory=\"las\"\n",
    "path = os.path.join(parent_dir, child_directory, directory)\n",
    "for files in listdir(path):\n",
    "    fullpath=os.path.join(path,files)\n",
    "    inFile = laspy.file.File(fullpath, mode = \"r\")\n",
    "    splitat = 10\n",
    "    s =files[0:splitat]\n",
    "    #read las as txt to implement voxel down sapling using o3d\n",
    "    suffix = '.xyz'\n",
    "    txtfullpath=os.path.join(parent_dir, \"txt/testdata\",s + suffix)\n",
    "    datasetfull = np.vstack([inFile.X/100, inFile.Y/100,inFile.Z/100]).transpose()\n",
    "    np.savetxt(txtfullpath, datasetfull)\n",
    "    pcd = o3d.io.read_point_cloud(txtfullpath)\n",
    "    #downsampling pc\n",
    "    downpcd = pcd.voxel_down_sample(voxel_size)\n",
    "    dataset = o3d.np.asarray(downpcd.points)[:,0:2]\n",
    "    zval=o3d.np.asarray(downpcd.points)[:,2]\n",
    "    splitat = 5\n",
    "    l, r =files[1:splitat], files[splitat:10]\n",
    "    #define extent of the pc\n",
    "    xmin=100*int(l)\n",
    "    ymin=100*int(r)\n",
    "    xmax=100*(int(l)+5)\n",
    "    ymax=100*(int(r)+5)\n",
    "    #find which polygons are inside boundary box of the overal pc\n",
    "    hits=list(shape.items(bbox=(xmin, ymin, xmax, ymax)))\n",
    "    zval=zval.tolist()\n",
    "    fullarray=[]\n",
    "    #iterate over these polygons to find which points in the point cloud\n",
    "    # lie inside\n",
    "    for polynum in range(len(hits)-1):\n",
    "        for j in range(len(hits[polynum][1]['geometry']['coordinates'])):\n",
    "            #print('polygon number',j+1,'with this id')\n",
    "            unpacklist=hits[polynum][1]['geometry']['coordinates'][j]\n",
    "            if len(unpacklist)==1:\n",
    "                unpacklist=unpacklist[0]\n",
    "            polygon=Polygon(unpacklist)\n",
    "            array = []\n",
    "            zeroarray=[]\n",
    "            for i in range(np.shape(dataset)[0]):\n",
    "                point=Point(dataset[i,:])\n",
    "                if point.within(polygon)==True:\n",
    "                    array.append(i)\n",
    "        fullarray.append(array)\n",
    "    dp=dataset.tolist()\n",
    "    getgen=[]\n",
    "    for ida in range(len(fullarray)):\n",
    "        for idx,l in enumerate(fullarray[ida]):\n",
    "    #append the feature type of the polygon to the points 3d coordinates\n",
    "            dp[l].extend((zval[l],hits[ida][1]['properties']['type']))\n",
    "    #if a point with no feature type then mark as feature type 0\n",
    "    for i in range(len(dp)):\n",
    "        if len(dp[i])==2:\n",
    "            dp[i].extend((zval[i],0))\n",
    "    splitat = 5\n",
    "    l, r =files[1:splitat], files[splitat:10]\n",
    "    #splice up the voxilised pointcloud into sectors\n",
    "    #define the extent of the sectors/chunks\n",
    "    xspace=(xmax-xmin)/cropnum\n",
    "    yspace=(ymax-ymin)/cropnum\n",
    "    ls=[]\n",
    "    #find which sectors contain points with labels\n",
    "    for k in range(len(dp)):\n",
    "        for i, j in itertools.product(range(cropnum-1), range(cropnum-1)):\n",
    "            if (xmin+xspace*(i)<dp[k][0]<xmin+xspace*(i+1)) & (ymin+yspace*(j)<dp[k][1]<ymin+yspace*(j+1)) & (dp[k][3]!=0):\n",
    "                ls.append((i,j)) if (i,j) not in ls else ls\n",
    "    getem=[]\n",
    "#extract only the points that lie inside sectors with labels\n",
    "    xspace=(xmax-xmin)/cropnum\n",
    "    yspace=(ymax-ymin)/cropnum\n",
    "    for s, t in ls:\n",
    "        get=[]\n",
    "        for k in range(len(dp)):\n",
    "            if (xmin+xspace*(s)<dp[k][0]<xmin+xspace*(s+1)) & (ymin+yspace*(t)<dp[k][1]<ymin+yspace*(t+1)):\n",
    "                get.append(dp[k])\n",
    "        getem.append(get)\n",
    "    #this section deals with points that have more than one label.\n",
    "    getem_dpl = [[] for _ in range(len(getem))]\n",
    "    for ia in range(len(getem)):\n",
    "        for ib in range(len(getem[ia])):\n",
    "            if len(getem[ia][ib])<5:\n",
    "                getem_dpl[ia].insert(ib,getem[ia][ib][0:4])\n",
    "            else:\n",
    "                ls=list(range(2,len(getem[ia][ib]),2))\n",
    "                for s,k in enumerate(ls):\n",
    "                    lr=[0,1,k,k+1]\n",
    "                    a=np.array(getem[ia][ib])[lr]\n",
    "                    getem_dpl[ia].append(list(a))\n",
    "    directory2=\"testdataout\"\n",
    "    child_directory2=\"txt\"\n",
    "    path2 = os.path.join(parent_dir, child_directory2, directory2)\n",
    "    #save as txt files\n",
    "    for i in range(len(getem_dpl)):\n",
    "        splitat = 10\n",
    "        s =files[0:splitat]\n",
    "        suffix = '.xyz'\n",
    "        txtfullpath2=os.path.join(parent_dir2, \"txt/testdataout\",s +'_'+str(i) + suffix)\n",
    "        print('Outputing:',txtfullpath2)\n",
    "        np.savetxt(txtfullpath2, getem_dpl[i])\n",
    "\n",
    "\n"
   ]
  }
 ]
}